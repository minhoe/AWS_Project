{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A binary to train MNIST using multiple GPUs with synchronous updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version :  1.12.0\n",
      "['/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3']\n"
     ]
    }
   ],
   "source": [
    "# TF and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "tf.set_random_seed(19)\n",
    "\n",
    "print('TF Version : ', tf.__version__)\n",
    "print(K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (60000, 28, 28)\n",
      "Class dataset :  (60000,)\n",
      "Testing data shape :  (10000, 28, 28)\n",
      "Class dataset :  (10000,)\n"
     ]
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Img size : 28 x 28 x 1\n",
    "# Num classes : 10\n",
    "\n",
    "print('Training data shape : ', train_images.shape)\n",
    "print('Class dataset : ', train_labels.shape)\n",
    "print('Testing data shape : ', test_images.shape)\n",
    "print('Class dataset : ', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Network Topologies\n",
    "n_hidden_1 = 128\n",
    "n_input    = 784\n",
    "n_classes  = 10\n",
    "display_step = 5\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, sess, name='aa', learning_rate=1e-3, batch_size=100):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size    = batch_size\n",
    "        \n",
    "        self.weights  = {\n",
    "            'wc1': tf.Variable(tf.random_normal([3, 3, 1, 64], stddev=0.1)),\n",
    "            'wd1': tf.Variable(tf.random_normal([14*14*64, n_classes], stddev=0.1))\n",
    "        }\n",
    "        self.biases   = {\n",
    "            'bc1': tf.Variable(tf.random_normal([64], stddev=0.1)),\n",
    "            'bd1': tf.Variable(tf.random_normal([n_classes], stddev=0.1))\n",
    "        }\n",
    "        \n",
    "        self.Build()\n",
    "        # Saver\n",
    "        self.save_step = 1;\n",
    "        self.savedir = \"nets/\"\n",
    "        #self.saver = tf.train.Saver(max_to_keep=3) \n",
    "        \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    \n",
    "    # Set the convolution process\n",
    "    def conv_simple(self, _input, _w, _b):\n",
    "        # Reshape input\n",
    "        _input_r = tf.reshape(_input, shape=[-1, 28, 28, 1])\n",
    "        # Convolution\n",
    "        _conv1 = tf.nn.conv2d(_input_r, _w['wc1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "        # Add-bias\n",
    "        _conv2 = tf.nn.bias_add(_conv1, _b['bc1'])\n",
    "        # Pass ReLu\n",
    "        _conv3 = tf.nn.relu(_conv2)\n",
    "        # Max-pooling\n",
    "        _pool  = tf.nn.max_pool(_conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        # Vectorize\n",
    "        _dense = tf.reshape(_pool, [-1, _w['wd1'].get_shape().as_list()[0]])\n",
    "        # Fully-connected layer\n",
    "        _out = tf.add(tf.matmul(_dense, _w['wd1']), _b['bd1'])\n",
    "        # Return everything\n",
    "        out = {\n",
    "            'input_r': _input_r, 'conv1': _conv1, 'conv2': _conv2, 'conv3': _conv3\n",
    "            , 'pool': _pool, 'dense': _dense, 'out': _out\n",
    "        }\n",
    "        return out\n",
    "    \n",
    "    # Build model and loss function\n",
    "    def Build(self):\n",
    "        # Set Inputs and Outputs\n",
    "        self.X = tf.placeholder(tf.float32, shape=[None, n_input], name='X')\n",
    "        self.Y = tf.placeholder(tf.float32, shape=[None, n_classes], name='Y')\n",
    "\n",
    "        # Set Layers\n",
    "        self._pred = self.conv_simple(self.X, self.weights, self.biases)['out']\n",
    "        \n",
    "        # Loss and Optimizers\n",
    "        self.cost = tf.nn.softmax_cross_entropy_with_logits_v2(logits=self._pred, labels=self.Y)\n",
    "        self.cost = tf.reduce_mean(self.cost)\n",
    "        \n",
    "        self.optm = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "        \n",
    "        self.corr = tf.equal(tf.argmax(self._pred, 1), tf.argmax(self.Y, 1))\n",
    "        self.accr = tf.reduce_mean(tf.cast(self.corr, tf.float32))\n",
    "\n",
    "        print('Model definition completed') # Check the grammar error above\n",
    "    \n",
    "    # Execute the forward process with batch dataset\n",
    "    def run_single_step(self, batch_xs, batch_ys):\n",
    "        _, avg_cost = sess.run(\n",
    "                        [self.optm, self.cost],\n",
    "                        feed_dict={self.X:batch_xs, self.Y:batch_ys})\n",
    "        return avg_cost\n",
    "    \n",
    "    def run_inside(self, tag, batch_xs):\n",
    "        N_TRN = len(batch_xs)\n",
    "        batch_xs = self.sess.run(tf.reshape(batch_xs, shape=(N_TRN,-1)))\n",
    "        print(batch_xs.shape)\n",
    "        result = self.sess.run(self.conv_simple(self.X, self.weights, self.biases), feed_dict={self.X:batch_xs})\n",
    "        return result[tag]\n",
    "    \n",
    "    def get_prediction(self, x_test, y_test):\n",
    "        print(\"Test Label: \", self.sess.run(tf.argmax(y_test, 1)))\n",
    "        print(\"Prediction Label: \", self.sess.run(tf.argmax(self.logits, 1), feed_dict={self.X: x_test}))\n",
    "        return \n",
    "    \n",
    "    def get_accuracy(self, x_test, y_test):\n",
    "        print(x_test.shape)\n",
    "        return self.sess.run(self.accr, feed_dict={self.X: x_test, self.Y: y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(train_images, train_labels, test_images, test_lables, \n",
    "            sess, name, learning_rate=1e-3, batch_size=100, training_epochs=100):\n",
    "    with tf.device('/cpu:0'):\n",
    "        N_TRN = len(train_labels)\n",
    "        N_TST = len(test_labels)\n",
    "\n",
    "        train_images_flat = sess.run(tf.reshape(train_images, shape=(N_TRN,-1)))\n",
    "        test_images_flat  = sess.run(tf.reshape(test_images, shape=(N_TST,-1)))\n",
    "        train_labels_1h   = sess.run(tf.one_hot(train_labels, depth=n_classes))\n",
    "        test_labels_1h    = sess.run(tf.one_hot(test_labels, depth=n_classes))\n",
    "        \n",
    "        #############\n",
    "        \n",
    "        with tf.variable_scope(tf.get_variable_scope()): \n",
    "            avg_cost = 0.0\n",
    "            num_batch = int(N_TRN / batch_size)\n",
    "\n",
    "            # Get random minibatch for each epoch\n",
    "            randindices = np.random.permutation(len(train_labels_1h))    \n",
    "\n",
    "            model = Model(sess, name, learning_rate=learning_rate, batch_size=batch_size)\n",
    "            \n",
    "            for i in range(num_batch):\n",
    "                # Obtain a batch\n",
    "                cur_indices = randindices[i*batch_size:(i+1)*batch_size]\n",
    "                batch_xs    = train_images_flat[cur_indices, :]\n",
    "                batch_ys    = train_labels_1h[cur_indices, :]            \n",
    "            \n",
    "                for i in range(4):\n",
    "                    with tf.device('/GPU:%d' % i):\n",
    "                        with tf.name_scope('%s_%d' % ('TOWER', i)) as scope:\n",
    "\n",
    "                            avg_cost_tmp = model.run_single_step(batch_xs, batch_ys)\n",
    "                            avg_cost += avg_cost_tmp / num_batch                    \n",
    "                            # Display training steps\n",
    "                            if True: #epoch % display_step == 0:\n",
    "                                train_acc = model.get_accuracy(batch_xs, batch_ys)\n",
    "                                test_acc  = model.get_accuracy(test_images_flat, test_labels_1h)\n",
    "\n",
    "                                print('Epoch: %03d/%03d cost: %0.9f train_acc: %.3f test_acc %.3f'\n",
    "                                      % (-1, training_epochs, avg_cost, train_acc, test_acc))                    \n",
    "\n",
    "#             # Minibatch learning    \n",
    "#             for epoch in range(training_epochs): \n",
    "\n",
    "\n",
    "#                 # Display training steps\n",
    "#                 if epoch % display_step == 0:\n",
    "#                     train_acc = model.get_accuracy(batch_xs, batch_ys)\n",
    "#                     test_acc  = model.get_accuracy(test_images_flat, test_labels_1h)\n",
    "\n",
    "#                     print('Epoch: %03d/%03d cost: %0.9f train_acc: %.3f test_acc %.3f'\n",
    "#                           % (epoch, training_epochs, avg_cost, train_acc, test_acc))\n",
    "\n",
    "#                 # Save net\n",
    "#                 if epoch % model.save_step == 0:\n",
    "#                     pass\n",
    "#                     #model.saver.save(sess, 'nets/cnn_mnist_simple.ckpt-' + str(epoch))\n",
    "        print('Done')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model definition completed\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 0.523303833 train_acc: 0.040 test_acc 0.097\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 1.024244741 train_acc: 0.050 test_acc 0.099\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 1.503737590 train_acc: 0.050 test_acc 0.100\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 1.962734019 train_acc: 0.050 test_acc 0.101\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 2.391527913 train_acc: 0.080 test_acc 0.102\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 2.802261709 train_acc: 0.100 test_acc 0.106\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 3.195162404 train_acc: 0.100 test_acc 0.111\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 3.570871023 train_acc: 0.100 test_acc 0.114\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 3.952977982 train_acc: 0.090 test_acc 0.119\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 4.324473546 train_acc: 0.100 test_acc 0.124\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 4.685608953 train_acc: 0.110 test_acc 0.128\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 5.036421738 train_acc: 0.110 test_acc 0.132\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 5.361720861 train_acc: 0.140 test_acc 0.135\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 5.678825582 train_acc: 0.140 test_acc 0.138\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 5.987460098 train_acc: 0.150 test_acc 0.141\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 6.287697398 train_acc: 0.200 test_acc 0.141\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 6.620891647 train_acc: 0.130 test_acc 0.144\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 6.946705907 train_acc: 0.130 test_acc 0.147\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 7.264954300 train_acc: 0.130 test_acc 0.150\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 7.575434748 train_acc: 0.140 test_acc 0.154\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 7.835591253 train_acc: 0.120 test_acc 0.157\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 8.089011790 train_acc: 0.110 test_acc 0.161\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 8.335431925 train_acc: 0.130 test_acc 0.164\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 8.575145264 train_acc: 0.130 test_acc 0.169\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 8.800647405 train_acc: 0.210 test_acc 0.174\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 9.021298498 train_acc: 0.200 test_acc 0.179\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 9.237011439 train_acc: 0.210 test_acc 0.184\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 9.447644119 train_acc: 0.240 test_acc 0.188\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 9.732041473 train_acc: 0.150 test_acc 0.193\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 10.010939331 train_acc: 0.140 test_acc 0.198\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 10.283639018 train_acc: 0.140 test_acc 0.203\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 10.549532013 train_acc: 0.150 test_acc 0.206\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 10.801427511 train_acc: 0.190 test_acc 0.209\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 11.049318797 train_acc: 0.190 test_acc 0.214\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 11.292736206 train_acc: 0.190 test_acc 0.219\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 11.531265157 train_acc: 0.200 test_acc 0.223\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 11.730947673 train_acc: 0.230 test_acc 0.228\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 11.926421458 train_acc: 0.230 test_acc 0.233\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 12.116901906 train_acc: 0.240 test_acc 0.238\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 12.301785711 train_acc: 0.250 test_acc 0.242\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 12.513887405 train_acc: 0.170 test_acc 0.248\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 12.720989126 train_acc: 0.190 test_acc 0.254\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 12.922793147 train_acc: 0.200 test_acc 0.260\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 13.118884265 train_acc: 0.210 test_acc 0.266\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 13.320648600 train_acc: 0.290 test_acc 0.272\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 13.519699961 train_acc: 0.300 test_acc 0.277\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 13.715753555 train_acc: 0.300 test_acc 0.283\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 13.908488146 train_acc: 0.310 test_acc 0.289\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 14.102415835 train_acc: 0.320 test_acc 0.294\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 14.293222872 train_acc: 0.320 test_acc 0.301\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 14.480506350 train_acc: 0.340 test_acc 0.306\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 14.664060504 train_acc: 0.360 test_acc 0.311\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 14.818005600 train_acc: 0.330 test_acc 0.315\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 14.969363480 train_acc: 0.340 test_acc 0.321\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 15.117447497 train_acc: 0.360 test_acc 0.327\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 15.261619759 train_acc: 0.370 test_acc 0.332\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 15.405072276 train_acc: 0.400 test_acc 0.337\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 15.545937335 train_acc: 0.400 test_acc 0.342\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 15.683857791 train_acc: 0.420 test_acc 0.347\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 15.818605461 train_acc: 0.430 test_acc 0.351\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 16.007778753 train_acc: 0.290 test_acc 0.357\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 16.194225858 train_acc: 0.290 test_acc 0.361\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 16.377410342 train_acc: 0.290 test_acc 0.365\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 16.556843185 train_acc: 0.300 test_acc 0.370\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 16.703713811 train_acc: 0.430 test_acc 0.374\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 16.847721799 train_acc: 0.430 test_acc 0.377\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 16.988324064 train_acc: 0.430 test_acc 0.379\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 17.125044810 train_acc: 0.430 test_acc 0.384\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 17.263436788 train_acc: 0.380 test_acc 0.387\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 17.400065041 train_acc: 0.380 test_acc 0.390\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 17.534255956 train_acc: 0.380 test_acc 0.393\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 17.665404154 train_acc: 0.380 test_acc 0.397\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 17.783490423 train_acc: 0.370 test_acc 0.401\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 17.899271838 train_acc: 0.380 test_acc 0.405\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 18.012331492 train_acc: 0.380 test_acc 0.408\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 18.122292442 train_acc: 0.390 test_acc 0.413\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 18.263912977 train_acc: 0.350 test_acc 0.418\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 18.402556597 train_acc: 0.370 test_acc 0.423\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 18.537620214 train_acc: 0.380 test_acc 0.431\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 18.668881925 train_acc: 0.380 test_acc 0.438\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 18.794600932 train_acc: 0.380 test_acc 0.444\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 18.917740949 train_acc: 0.410 test_acc 0.450\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 19.038087616 train_acc: 0.410 test_acc 0.456\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 19.155500348 train_acc: 0.430 test_acc 0.460\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 19.243669936 train_acc: 0.520 test_acc 0.465\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 19.330469869 train_acc: 0.510 test_acc 0.470\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 19.415452353 train_acc: 0.530 test_acc 0.475\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 19.498212980 train_acc: 0.550 test_acc 0.478\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 19.603839327 train_acc: 0.470 test_acc 0.481\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 19.707563833 train_acc: 0.480 test_acc 0.485\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 19.808864415 train_acc: 0.490 test_acc 0.488\n",
      "(100, 784)\n",
      "(10000, 784)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: -01/100 cost: 19.907477824 train_acc: 0.490 test_acc 0.493\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 20.032794609 train_acc: 0.440 test_acc 0.496\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 20.156305885 train_acc: 0.440 test_acc 0.499\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 20.277592723 train_acc: 0.450 test_acc 0.501\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 20.396321615 train_acc: 0.450 test_acc 0.503\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 20.496707935 train_acc: 0.510 test_acc 0.501\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 20.595291138 train_acc: 0.530 test_acc 0.503\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 20.691830076 train_acc: 0.510 test_acc 0.506\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 20.786230570 train_acc: 0.520 test_acc 0.507\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 20.895679398 train_acc: 0.530 test_acc 0.508\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 21.003919830 train_acc: 0.530 test_acc 0.512\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 21.110461235 train_acc: 0.550 test_acc 0.514\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 21.214883474 train_acc: 0.550 test_acc 0.516\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 21.300840448 train_acc: 0.560 test_acc 0.519\n",
      "(100, 784)\n",
      "(10000, 784)\n",
      "Epoch: -01/100 cost: 21.385584456 train_acc: 0.560 test_acc 0.522\n",
      "(100, 784)\n",
      "(10000, 784)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-8aecdb4c9eed>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(train_images, train_labels, test_images, test_lables, sess, name, learning_rate, batch_size, training_epochs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#epoch % display_step == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                                 \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                                 \u001b[0mtest_acc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels_1h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                                 print('Epoch: %03d/%03d cost: %0.9f train_acc: %.3f test_acc %.3f'\n",
      "\u001b[0;32m<ipython-input-3-9689471bc1a2>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(self, x_test, y_test)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NAME = 'MNIST'\n",
    "\n",
    "# Session\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "# Train the model\n",
    "model = trainer(train_images, train_labels, \n",
    "                test_images, test_labels, \n",
    "                sess, NAME,\n",
    "                learning_rate=1e-4,  batch_size=100, training_epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
